{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e77f8b7-5422-4637-8819-15430e3c28c9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a0481-9701-4d64-bbd1-8360fa05f4e5",
   "metadata": {},
   "source": [
    "## Data And Library Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084b3be0-25e5-44a9-81bc-ede9ad3568dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sn\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "plt.style.use('dark_background')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20fb0ad-9d3d-44e3-bd2c-499ecf6f755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>CONSTITUENCY</th>\n",
       "      <th>NAME</th>\n",
       "      <th>WINNER</th>\n",
       "      <th>PARTY</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>CRIMINAL\\nCASES</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ASSETS</th>\n",
       "      <th>LIABILITIES</th>\n",
       "      <th>GENERAL\\nVOTES</th>\n",
       "      <th>POSTAL\\nVOTES</th>\n",
       "      <th>TOTAL\\nVOTES</th>\n",
       "      <th>OVER TOTAL ELECTORS \\nIN CONSTITUENCY</th>\n",
       "      <th>OVER TOTAL VOTES POLLED \\nIN CONSTITUENCY</th>\n",
       "      <th>TOTAL ELECTORS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>SOYAM BAPU RAO</td>\n",
       "      <td>1</td>\n",
       "      <td>BJP</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>MALE</td>\n",
       "      <td>52</td>\n",
       "      <td>52.0</td>\n",
       "      <td>ST</td>\n",
       "      <td>12th Pass</td>\n",
       "      <td>Rs 30,99,414\\n ~ 30 Lacs+</td>\n",
       "      <td>Rs 2,31,450\\n ~ 2 Lacs+</td>\n",
       "      <td>376892</td>\n",
       "      <td>482</td>\n",
       "      <td>377374</td>\n",
       "      <td>25.330684</td>\n",
       "      <td>35.468248</td>\n",
       "      <td>1489790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>Godam Nagesh</td>\n",
       "      <td>0</td>\n",
       "      <td>TRS</td>\n",
       "      <td>Car</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>ST</td>\n",
       "      <td>Post Graduate</td>\n",
       "      <td>Rs 1,84,77,888\\n ~ 1 Crore+</td>\n",
       "      <td>Rs 8,47,000\\n ~ 8 Lacs+</td>\n",
       "      <td>318665</td>\n",
       "      <td>149</td>\n",
       "      <td>318814</td>\n",
       "      <td>21.399929</td>\n",
       "      <td>29.964370</td>\n",
       "      <td>1489790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>RATHOD RAMESH</td>\n",
       "      <td>0</td>\n",
       "      <td>INC</td>\n",
       "      <td>Hand</td>\n",
       "      <td>MALE</td>\n",
       "      <td>3</td>\n",
       "      <td>52.0</td>\n",
       "      <td>ST</td>\n",
       "      <td>12th Pass</td>\n",
       "      <td>Rs 3,64,91,000\\n ~ 3 Crore+</td>\n",
       "      <td>Rs 1,53,00,000\\n ~ 1 Crore+</td>\n",
       "      <td>314057</td>\n",
       "      <td>181</td>\n",
       "      <td>314238</td>\n",
       "      <td>21.092771</td>\n",
       "      <td>29.534285</td>\n",
       "      <td>1489790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>NOTA</td>\n",
       "      <td>0</td>\n",
       "      <td>NOTA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13030</td>\n",
       "      <td>6</td>\n",
       "      <td>13036</td>\n",
       "      <td>0.875023</td>\n",
       "      <td>1.225214</td>\n",
       "      <td>1489790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>AGRA</td>\n",
       "      <td>Satyapal Singh Baghel</td>\n",
       "      <td>1</td>\n",
       "      <td>BJP</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>MALE</td>\n",
       "      <td>5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Rs 7,42,74,036\\n ~ 7 Crore+</td>\n",
       "      <td>Rs 86,06,522\\n ~ 86 Lacs+</td>\n",
       "      <td>644459</td>\n",
       "      <td>2416</td>\n",
       "      <td>646875</td>\n",
       "      <td>33.383823</td>\n",
       "      <td>56.464615</td>\n",
       "      <td>1937690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           STATE CONSTITUENCY                   NAME  WINNER PARTY SYMBOL  \\\n",
       "0      Telangana     ADILABAD         SOYAM BAPU RAO       1   BJP  Lotus   \n",
       "1      Telangana     ADILABAD           Godam Nagesh       0   TRS    Car   \n",
       "2      Telangana     ADILABAD          RATHOD RAMESH       0   INC   Hand   \n",
       "3      Telangana     ADILABAD                   NOTA       0  NOTA    NaN   \n",
       "4  Uttar Pradesh         AGRA  Satyapal Singh Baghel       1   BJP  Lotus   \n",
       "\n",
       "  GENDER CRIMINAL\\nCASES   AGE CATEGORY      EDUCATION  \\\n",
       "0   MALE              52  52.0       ST      12th Pass   \n",
       "1   MALE               0  54.0       ST  Post Graduate   \n",
       "2   MALE               3  52.0       ST      12th Pass   \n",
       "3    NaN             NaN   NaN      NaN            NaN   \n",
       "4   MALE               5  58.0       SC      Doctorate   \n",
       "\n",
       "                        ASSETS                  LIABILITIES  GENERAL\\nVOTES  \\\n",
       "0    Rs 30,99,414\\n ~ 30 Lacs+      Rs 2,31,450\\n ~ 2 Lacs+          376892   \n",
       "1  Rs 1,84,77,888\\n ~ 1 Crore+      Rs 8,47,000\\n ~ 8 Lacs+          318665   \n",
       "2  Rs 3,64,91,000\\n ~ 3 Crore+  Rs 1,53,00,000\\n ~ 1 Crore+          314057   \n",
       "3                          NaN                          NaN           13030   \n",
       "4  Rs 7,42,74,036\\n ~ 7 Crore+    Rs 86,06,522\\n ~ 86 Lacs+          644459   \n",
       "\n",
       "   POSTAL\\nVOTES  TOTAL\\nVOTES  OVER TOTAL ELECTORS \\nIN CONSTITUENCY  \\\n",
       "0            482        377374                              25.330684   \n",
       "1            149        318814                              21.399929   \n",
       "2            181        314238                              21.092771   \n",
       "3              6         13036                               0.875023   \n",
       "4           2416        646875                              33.383823   \n",
       "\n",
       "   OVER TOTAL VOTES POLLED \\nIN CONSTITUENCY  TOTAL ELECTORS  \n",
       "0                                  35.468248         1489790  \n",
       "1                                  29.964370         1489790  \n",
       "2                                  29.534285         1489790  \n",
       "3                                   1.225214         1489790  \n",
       "4                                  56.464615         1937690  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('LS_2.0.csv', header = 0)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fca1564-e2e6-4a21-9992-a6f5e370bf24",
   "metadata": {},
   "source": [
    "## Missing Values And Cleaning up The Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461ea517-b67f-4264-9339-997eeb086462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE                                          0\n",
       "CONSTITUENCY                                   0\n",
       "NAME                                           0\n",
       "WINNER                                         0\n",
       "PARTY                                          0\n",
       "SYMBOL                                       245\n",
       "GENDER                                       245\n",
       "CRIMINAL\\nCASES                              245\n",
       "AGE                                          245\n",
       "CATEGORY                                     245\n",
       "EDUCATION                                    245\n",
       "ASSETS                                       245\n",
       "LIABILITIES                                  245\n",
       "GENERAL\\nVOTES                                 0\n",
       "POSTAL\\nVOTES                                  0\n",
       "TOTAL\\nVOTES                                   0\n",
       "OVER TOTAL ELECTORS \\nIN CONSTITUENCY          0\n",
       "OVER TOTAL VOTES POLLED \\nIN CONSTITUENCY      0\n",
       "TOTAL ELECTORS                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bf033d-6f80-4385-8c5f-be70f4654355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOTA'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.SYMBOL.isnull()==True]['NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673dbad4-710b-484c-b2a4-49089447e2d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               STATE    CONSTITUENCY  NAME  WINNER PARTY SYMBOL GENDER  \\\n",
      "3          Telangana        ADILABAD  NOTA       0  NOTA    NaN    NaN   \n",
      "14           Gujarat  AHMEDABAD WEST  NOTA       0  NOTA    NaN    NaN   \n",
      "39       West Bengal     ALIPURDUARS  NOTA       0  NOTA    NaN    NaN   \n",
      "46       Uttarakhand          ALMORA  NOTA       0  NOTA    NaN    NaN   \n",
      "54    Andhra Pradesh      AMALAPURAM  NOTA       0  NOTA    NaN    NaN   \n",
      "...              ...             ...   ...     ...   ...    ...    ...   \n",
      "2225      Tamil Nadu    VIRUDHUNAGAR  NOTA       0  NOTA    NaN    NaN   \n",
      "2230  Andhra Pradesh   VISAKHAPATNAM  NOTA       0  NOTA    NaN    NaN   \n",
      "2235  Andhra Pradesh    VIZIANAGARAM  NOTA       0  NOTA    NaN    NaN   \n",
      "2241       Telangana        WARANGAL  NOTA       0  NOTA    NaN    NaN   \n",
      "2262       Telangana       ZAHIRABAD  NOTA       0  NOTA    NaN    NaN   \n",
      "\n",
      "     CRIMINAL\\nCASES  AGE CATEGORY EDUCATION ASSETS LIABILITIES  \\\n",
      "3                NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "14               NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "39               NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "46               NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "54               NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "...              ...  ...      ...       ...    ...         ...   \n",
      "2225             NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "2230             NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "2235             NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "2241             NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "2262             NaN  NaN      NaN       NaN    NaN         NaN   \n",
      "\n",
      "      GENERAL\\nVOTES  POSTAL\\nVOTES  TOTAL\\nVOTES  \\\n",
      "3              13030              6         13036   \n",
      "14             14580            139         14719   \n",
      "39             21147             28         21175   \n",
      "46             15311            194         15505   \n",
      "54             16427             41         16468   \n",
      "...              ...            ...           ...   \n",
      "2225           17087            205         17292   \n",
      "2230           16626             20         16646   \n",
      "2235           29468             33         29501   \n",
      "2241           18764             37         18801   \n",
      "2262           11138              2         11140   \n",
      "\n",
      "      OVER TOTAL ELECTORS \\nIN CONSTITUENCY  \\\n",
      "3                                  0.875023   \n",
      "14                                 0.895688   \n",
      "39                                 1.284592   \n",
      "46                                 1.158985   \n",
      "54                                 1.128288   \n",
      "...                                     ...   \n",
      "2225                               1.165028   \n",
      "2230                               0.909966   \n",
      "2235                               1.961529   \n",
      "2241                               1.127990   \n",
      "2262                               0.743328   \n",
      "\n",
      "      OVER TOTAL VOTES POLLED \\nIN CONSTITUENCY  TOTAL ELECTORS  \n",
      "3                                      1.225214         1489790  \n",
      "14                                     1.473030         1643317  \n",
      "39                                     1.533114         1648383  \n",
      "46                                     2.215611         1337808  \n",
      "54                                     1.333044         1459556  \n",
      "...                                         ...             ...  \n",
      "2225                                   1.607174         1484256  \n",
      "2230                                   1.342505         1829300  \n",
      "2235                                   2.413302         1503980  \n",
      "2241                                   1.770886         1666770  \n",
      "2262                                   1.066535         1498666  \n",
      "\n",
      "[245 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'NAME' column contains 'NOTA'\n",
    "nota_rows = df[df['NAME'].str.contains('NOTA', na=False)]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(nota_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d2e33c-8649-4c17-a25a-95aac3ae9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOTA = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e052a9c-221d-4b9a-b91c-a5d703d03dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'NAME' column contains 'NOTA'\n",
    "df= df[~df['NAME'].str.contains('NOTA', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a10888d-35ef-4969-a5c0-6c26962c994a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_REMOVE_NOTA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 12\u001b[0m df_REMOVE_NOTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASSETS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_REMOVE_NOTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASSETS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply((value_cleaner))\n\u001b[0;32m     13\u001b[0m df_REMOVE_NOTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIABILITIES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_REMOVE_NOTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIABILITIES\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply((value_cleaner))\n\u001b[0;32m     14\u001b[0m df_REMOVE_NOTA\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_REMOVE_NOTA' is not defined"
     ]
    }
   ],
   "source": [
    "#Cleaning up the Assets and Liabilities columns\n",
    "def value_cleaner(x):\n",
    "    try:\n",
    "        str_temp = (x.split('Rs')[1].split('\\n')[0].strip())\n",
    "        str_temp_2 = ''\n",
    "        for i in str_temp.split(\",\"):\n",
    "            str_temp_2 = str_temp_2+i\n",
    "        return str_temp_2\n",
    "    except:\n",
    "        x = 0\n",
    "        return x\n",
    "df_REMOVE_NOTA['ASSETS'] = df_REMOVE_NOTA['ASSETS'].apply((value_cleaner))\n",
    "df_REMOVE_NOTA['LIABILITIES'] = df_REMOVE_NOTA['LIABILITIES'].apply((value_cleaner))\n",
    "df_REMOVE_NOTA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddf71d-277e-4d77-927e-184fdcfcfd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the Columns\n",
    "df.rename(columns={\"CRIMINAL\\nCASES\": \"CRIMINAL CASES\", \"GENERAL\\nVOTES\": \"GENERAL VOTES\", \"POSTAL\\nVOTES\": \"POSTAL VOTES\",\"TOTAL\\nVOTES\": \"TOTAL VOTES\",\"OVER TOTAL ELECTORS \\nIN CONSTITUENCY\": \"OVER TOTAL ELECTORS IN CONSTITUENCY\",\"OVER TOTAL VOTES POLLED \\nIN CONSTITUENCY\": \"OVER TOTAL VOTES POLLED IN CONSTITUENCY\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b73ae-9d85-4aa7-8a7c-b797b63fc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the Educational Qualification of the election contestants\n",
    "df.EDUCATION.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c96377-c74d-4328-a7d5-32054e51971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.EDUCATION.replace({'Post Graduate\\n':'Post Graduate'},inplace=True)\n",
    "df.EDUCATION.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb3cdb-eb44-4be3-9622-bd4f0c86addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data types for the analysis\n",
    "df['ASSETS']=pd.to_numeric(df['ASSETS'])\n",
    "df['LIABILITIES']=pd.to_numeric(df['LIABILITIES'])\n",
    "df['CRIMINAL CASES'].replace({np.NaN:0})\n",
    "df['CRIMINAL CASES'] = pd.to_numeric(df['CRIMINAL CASES'], errors='coerce').fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189bcb3-be8e-4ee1-a4f4-724597a4cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07e77b-9362-41c7-8c79-72526940b684",
   "metadata": {},
   "source": [
    "# The Analysis Using Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e1141-576b-4a64-823d-1bb751075d14",
   "metadata": {},
   "source": [
    "## State and Constituency Level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae875abc-dc1a-4c74-8ee8-b1dcc5c2f187",
   "metadata": {},
   "source": [
    "### What is the distribution of Constituencies over all the states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c9ccc-c447-4851-beb7-7732d5a493d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117cc03-9c70-402b-b7b0-2601c3234e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Group by state and count the number of constituencies in each state\n",
    "st_con = df.groupby('STATE').apply(lambda x: x['CONSTITUENCY'].nunique()).reset_index(name='# Constituency')\n",
    "\n",
    "# Read the shapefile\n",
    "shp_gdf = gpd.read_file('Indian_States.shp')\n",
    "\n",
    "# Merge shapefile GeoDataFrame with your DataFrame\n",
    "merged = shp_gdf.set_index('st_nm').join(st_con.set_index('STATE'))\n",
    "\n",
    "# Plotting the GeoDataFrame with Matplotlib\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15, 10))  # 15 inches wide, 10 inches high\n",
    "\n",
    "# Set the figure and axis background color to gray\n",
    "fig.patch.set_facecolor('gray')\n",
    "ax1.set_facecolor('gray')\n",
    "\n",
    "merged.plot(column='# Constituency', cmap='inferno_r', linewidth=0.5, ax=ax1, edgecolor='0.2', legend=True)\n",
    "ax1.set_title('State-wise Distribution of Indian Constituencies', fontdict={'fontsize': '15', 'fontweight': '3'})\n",
    "ax1.axis('off')\n",
    "\n",
    "# Save the Matplotlib figure to an image file\n",
    "fig.savefig(\"matplotlib_figure.png\", bbox_inches='tight', facecolor=fig.get_facecolor())\n",
    "\n",
    "# Close the Matplotlib figure\n",
    "plt.close(fig)\n",
    "\n",
    "# Sorting the DataFrame for Plotly bar chart\n",
    "st_con.sort_values(by='# Constituency', ascending=True, inplace=True)\n",
    "\n",
    "# Plotting the bar chart with Plotly\n",
    "fig2 = px.bar(st_con, y='STATE', x='# Constituency',  # Switched x and y parameters\n",
    "              color='# Constituency',\n",
    "              labels={'pop': 'Constituencies of India'},\n",
    "              orientation='h',  # Set orientation to horizontal\n",
    "              )\n",
    "\n",
    "fig2.update_layout(\n",
    "    title_text='Statewise distribution of the Constituencies all over India',\n",
    "    template='plotly_dark',\n",
    "    plot_bgcolor='gray',\n",
    "    paper_bgcolor='gray',\n",
    "    width=550,  # Set the width of the plot\n",
    "    height=650  # Set the height of the plot (same as Matplotlib figure)\n",
    ")\n",
    "\n",
    "# Save the Plotly figure to an HTML file\n",
    "fig2_html = fig2.to_html(full_html=False)\n",
    "\n",
    "# Display both plots side by side\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "    <div style=\"width: 50%;\">\n",
    "        <img src=\"matplotlib_figure.png\" style=\"width: 100%; height: 650px;\">\n",
    "    </div>\n",
    "    <div style=\"width: 50%;\">\n",
    "        {fig2_html}\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2a8b4-5218-47ea-87a4-deceb1fea34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8121f37b-bfff-46f9-afa1-8f995c7aca2c",
   "metadata": {},
   "source": [
    "**Observation:** Uttar Pradesh, Maharashtra and West Bengal- The sates have the most number of constituencies. There exists a direct relationship of count of constituencies and population- The constituencies are divided based on the population of 1971- and this shall remain till the year 2026. Although currently Bihar has a higher population, West Bengal has the 3rd highest constituency count based on the above fact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fc907-1cc9-48cd-8e14-09910bde9935",
   "metadata": {},
   "source": [
    "### Lets create a Sunburst image of all the States and Constituencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf0b8e-b969-4c75-a30e-c8771937d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the required columns from the DataFrame 'df'\n",
    "st_con_vt = df[['STATE', 'CONSTITUENCY', 'TOTAL ELECTORS']]\n",
    "\n",
    "# Create a sunburst plot using Plotly Express\n",
    "fig = px.sunburst(\n",
    "    st_con_vt,                    # The DataFrame to use for the plot\n",
    "    path=['STATE', 'CONSTITUENCY'], # Define the hierarchical structure of the sunburst (STATE -> CONSTITUENCY)\n",
    "    values='TOTAL ELECTORS',       # Define the values to aggregate (TOTAL ELECTORS)\n",
    "    color='TOTAL ELECTORS',        # Use 'TOTAL ELECTORS' to determine the color of the segments\n",
    "    color_continuous_scale='viridis_r' # Set the color scale to 'viridis_r' (reversed Viridis)\n",
    ")\n",
    "\n",
    "# Update the layout of the plot\n",
    "fig.update_layout(\n",
    "    title_text='Sunburst Image of State and Constituency by Voters', # Set the title of the plot\n",
    "    template='plotly_dark',                                         # Use the 'plotly_dark' template for the plot's theme\n",
    "    width=1050,  # Set the width of the plot\n",
    "    height=750  # Set the height of the plot\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de773b1d-8b74-4f31-8312-9daeacd256b2",
   "metadata": {},
   "source": [
    "## Party Level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeeddf1-b50b-4593-87e2-5d6aee4d8b37",
   "metadata": {},
   "source": [
    "### Which Parties have been present in most constituencies and States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9976317-e020-4475-8be5-714c7edd71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'PARTY' and count the number of unique 'CONSTITUENCY' entries\n",
    "prty_cnt = df.groupby('PARTY').agg({'CONSTITUENCY': 'count', 'STATE': 'nunique'}).reset_index()\n",
    "prty_cnt.columns = ['PARTY', '# Constituency', '# State']\n",
    "\n",
    "# Sort the parties by the number of constituencies they are contesting in, in descending order\n",
    "prty_top_all = prty_cnt.nlargest(25, '# Constituency')\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(prty_top_all, x='# Constituency', y='# State', color='# State', size='# Constituency',\n",
    "                 hover_data=['PARTY'], title='Constituency vs Statewise participation for Top Political Parties',\n",
    "                 template='plotly_dark', labels={'# Constituency': 'Constituency Count', '# State': 'State Count'})\n",
    "fig.update_layout(plot_bgcolor='gray', paper_bgcolor='gray')\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb2551-c7a1-4277-8160-ddb7ce3cc18e",
   "metadata": {},
   "source": [
    "**Observation :** The Bharatiya Janata Party (BJP) and Indian National Congress (INC) have participated in the most number of constituencies all over India. While BJP leads in the number of constituency contested, INC wins in terms of the number of States. While these are the major parties to contest almost all over India, we see the rest of the parties have restricted themselves to a handfull of states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954166d3-45a4-460a-a796-243e054cecf1",
   "metadata": {},
   "source": [
    "### Which party has won the most constituencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3b3a9-72a2-44b7-a2f5-bd2f14b06d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'PARTY' and sum the 'WINNER' column to get the total wins per party\n",
    "part_win = df.groupby('PARTY')['WINNER'].sum().nlargest(15).reset_index(name='# Wins')\n",
    "\n",
    "# Create a bar plot\n",
    "fig = px.bar(part_win, x='PARTY', y='# Wins', color='# Wins',\n",
    "             title='Win Counts by Political Party in 2019', template='plotly_dark')\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff783e7-aba6-4d67-919e-74e7353c09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'BJP', 'INC', 'DMK', 'AITC','YSRCP', 'SHS','JD(U)', 'BJD', 'BSP', 'TRS', 'LJP', 'CPI(M)', 'NCP', 'SP', 'IND'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d66ef-611e-4798-9484-7527d56b5cd2",
   "metadata": {},
   "source": [
    "**Observation:** As seen from the data, In 2019, BJP has won the maximum constituencies all over India. The Image below the introduction also suggests the same. The distribution of all the parties is presented below. INC, who stood 2nd in the number of victories had only 52, which is practically 1/6th of the constituencies won by BJP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87793d-c4e2-40fc-ad5b-f6efeb64689d",
   "metadata": {},
   "source": [
    "### What has been the general Win vs Loss relationship for the Parties in 2019?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc1994-8f91-414c-8f7b-789b38af8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'prty_cnt' and 'part_win' DataFrames on 'PARTY' column\n",
    "prty_cnt_win = pd.merge(prty_cnt, part_win, on='PARTY')\n",
    "\n",
    "# Calculate the number of lost constituencies for each party\n",
    "prty_cnt_win['Lost'] = prty_cnt_win['# Constituency'] - prty_cnt_win['# Wins']\n",
    "\n",
    "# Create DataFrames for won and lost constituencies\n",
    "prty_wins_cnt = prty_cnt_win[['PARTY', '# Wins']].copy()\n",
    "prty_loss_cnt = prty_cnt_win[['PARTY', 'Lost']].copy()\n",
    "\n",
    "# Add a 'Verdict' column to indicate whether it's a won or lost constituency\n",
    "prty_wins_cnt['Verdict'] = 'Constituency Won'\n",
    "prty_loss_cnt['Verdict'] = 'Constituency Lost'\n",
    "\n",
    "# Rename columns\n",
    "prty_wins_cnt.columns = ['Party', 'Counts', 'Verdict']\n",
    "prty_loss_cnt.columns = ['Party', 'Counts', 'Verdict']\n",
    "\n",
    "# Select top 15 parties for both wins and losses\n",
    "top_prty_wins_cnt = prty_wins_cnt.head(15)\n",
    "prty_loss_cnt_cnt = prty_loss_cnt.head(15)\n",
    "\n",
    "# Concatenate DataFrames for wins and losses\n",
    "prt_win_loss = pd.concat([top_prty_wins_cnt, prty_loss_cnt_cnt])\n",
    "\n",
    "# Create a bar plot\n",
    "fig = px.bar(prt_win_loss, x='Party', y='Counts', color='Verdict')\n",
    "\n",
    "# Update the layout of the plot\n",
    "fig.update_layout(\n",
    "    title_text='Win vs Loss Analysis for the Top Parties',  # Set the plot title\n",
    "    template='plotly_dark'                                 # Use the 'plotly_dark' template for the plot's theme\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3b541-0bb3-4cce-ba54-d4953a7547e4",
   "metadata": {},
   "source": [
    "### What has been the performance of the Parties Statewise in Uttar Pradesh, Maharashtra and West Bengal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e71fc-a94b-4d06-a118-e0a6c14e9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Filter the DataFrame for Uttar Pradesh, Maharashtra, and West Bengal\n",
    "selected_states = ['Uttar Pradesh', 'Maharashtra', 'West Bengal']\n",
    "df_selected_states = df[df['STATE'].isin(selected_states)]\n",
    "\n",
    "# Group by 'PARTY' and 'STATE' and count the number of seats\n",
    "party_state_performance = df_selected_states.groupby(['PARTY', 'STATE']).size().reset_index(name='Performance')\n",
    "\n",
    "# Create a bar plot\n",
    "fig = px.bar(party_state_performance, x='PARTY', y='Performance', color='STATE',\n",
    "             title='Performance of Parties Statewise in Uttar Pradesh, Maharashtra, and West Bengal',\n",
    "             labels={'Performance': 'Number of Seats', 'PARTY': 'Party'},\n",
    "             template='plotly_dark')\n",
    "\n",
    "# Sort the parties by their total performance in descending order\n",
    "sorted_parties = party_state_performance.groupby('PARTY')['Performance'].sum().sort_values(ascending=False).index\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=sorted_parties)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b84276-a616-44a2-957a-de172ad8b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Filter the DataFrame for Uttar Pradesh, Maharashtra, West Bengal, Bihar, Tamil Nadu, Madhya Pradesh, Andhra Pradesh, and NCT OF Delhi\n",
    "selected_states = ['Uttar Pradesh', 'Maharashtra', 'West Bengal', 'Bihar', 'Tamil Nadu', 'Madhya Pradesh', 'Andhra Pradesh', 'NCT OF Delhi']\n",
    "df_selected_states = df[df['STATE'].isin(selected_states)]\n",
    "\n",
    "# Group by 'PARTY' and 'STATE' and count the number of seats\n",
    "party_state_performance = df_selected_states.groupby(['PARTY', 'STATE']).size().reset_index(name='Performance')\n",
    "\n",
    "# Calculate the total performance of each party across all states\n",
    "party_performance_total = party_state_performance.groupby('PARTY')['Performance'].sum().reset_index(name='Total Performance')\n",
    "\n",
    "# Select the top 15 parties based on total performance\n",
    "top_15_parties = party_performance_total.nlargest(20, 'Total Performance')['PARTY']\n",
    "\n",
    "# Filter the DataFrame to include only the rows corresponding to the top 15 parties\n",
    "party_state_performance_top15 = party_state_performance[party_state_performance['PARTY'].isin(top_15_parties)]\n",
    "\n",
    "# Create a bar plot\n",
    "fig = px.bar(party_state_performance_top15, x='PARTY', y='Performance', color='STATE',\n",
    "             title='Top 15 Parties: Performance Statewise',\n",
    "             labels={'Performance': 'Number of Seats', 'PARTY': 'Party'},\n",
    "             template='plotly_dark')\n",
    "\n",
    "# Sort the parties by their total performance in descending order\n",
    "sorted_parties = party_state_performance_top15.groupby('PARTY')['Performance'].sum().sort_values(ascending=False).index\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=sorted_parties)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f259b6-c6b1-48d5-808c-9b772025bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Filter the DataFrame for Uttar Pradesh, Maharashtra, and West Bengal\n",
    "selected_states = ['Uttar Pradesh', 'Maharashtra', 'West Bengal']\n",
    "df_selected_states = df[df['STATE'].isin(selected_states)]\n",
    "\n",
    "# Group by 'PARTY' and 'STATE' and count the number of winners\n",
    "party_state_counts = df_selected_states[df_selected_states['WINNER'] == 1].groupby(['PARTY', 'STATE']).size().reset_index(name='Counts')\n",
    "\n",
    "# Select top 15 parties based on the total counts of winners\n",
    "top_15_parties = party_state_counts.groupby('PARTY')['Counts'].sum().nlargest(15).index\n",
    "\n",
    "# Filter the DataFrame to include only the top 15 parties\n",
    "party_state_counts_top15 = party_state_counts[party_state_counts['PARTY'].isin(top_15_parties)]\n",
    "# Create a bar plot\n",
    "fig = px.bar(party_state_counts_top15, x='PARTY', y='Counts', color='STATE',\n",
    "             title='Top 15 Parties: Number of Winners in Uttar Pradesh, Maharashtra, and West Bengal',\n",
    "             labels={'Counts': 'Number of Winners', 'PARTY': 'Top 15 Parties', 'STATE': 'State'},\n",
    "             template='plotly_dark')\n",
    "\n",
    "# Sort the parties by their total performance in descending order\n",
    "sorted_parties = party_state_counts_top15.groupby('PARTY')['Counts'].sum().sort_values(ascending=False).index\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=sorted_parties)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7bcee-404c-409d-a36f-4f7c4a0b8118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4b89c4e-47cc-427e-8146-e2d28facb800",
   "metadata": {},
   "source": [
    "**Observation:** As seen in the above chart, the 2019 elections have been extremely lucky for parties like BJP,SHS or DMK. But it has been a major failure for the rest of the parties, where they have lost more than they won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc0a5a-b269-40e2-9de1-d1a36c1c2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter rows where 'NAME' column contains 'NOTA'\n",
    "nota_rows = df_NOTA[df_NOTA['NAME'].str.contains('NOTA', na=False)]\n",
    "\n",
    "# Group by 'STATE' and sum 'TOTAL\\nVOTES'\n",
    "statewise_votes = nota_rows.groupby('STATE')['TOTAL\\nVOTES'].sum().reset_index()\n",
    "\n",
    "# Sort the data by 'TOTAL\\nVOTES' for better visualization\n",
    "statewise_votes = statewise_votes.sort_values(by='TOTAL\\nVOTES', ascending=False)\n",
    "\n",
    "colors = plt.cm.YlGnBu(np.linspace(0, 1, len(statewise_votes)))\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(statewise_votes['STATE'], statewise_votes['TOTAL\\nVOTES'], color=colors)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Total NOTA Votes')\n",
    "plt.title('State-wise NOTA Vote Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d722a2c6-77bf-4cbc-acf7-67b64efa511a",
   "metadata": {},
   "source": [
    "## Politician Level Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd4d66-49af-442e-92b8-d1ec01a33280",
   "metadata": {},
   "source": [
    "### What is the Gender Ratio of the Contestants? Also the Gender Ratio of the Winners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea51c8-addc-40a4-849b-46bcc0eb06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gndr = df\n",
    "# Calculate overall gender counts\n",
    "gndr_overall = df_gndr.groupby('GENDER')['NAME'].count().reset_index(name='Counts')\n",
    "gndr_overall['Category'] = 'Overall Gender Ratio'\n",
    "# Filter out winners\n",
    "winners = df_gndr[df_gndr['WINNER'] == 1]\n",
    "# Calculate gender counts for winners\n",
    "gndr_winner = winners.groupby('GENDER')['NAME'].count().reset_index(name='Counts')\n",
    "gndr_winner['Category'] = 'Winning Gender Ratio'\n",
    "# Concatenate overall and winner gender counts\n",
    "gndr_overl_win = pd.concat([gndr_winner, gndr_overall])\n",
    "# Create a grouped bar plot\n",
    "fig = px.bar(gndr_overl_win, x='GENDER', y='Counts', color='Category', barmode='group')\n",
    "fig.update_layout(\n",
    "    title_text='Participation vs Win Counts analysis for the Genders',  # Set the plot title\n",
    "    template='plotly_dark')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7df3e8-d547-41e7-8ed9-33275c84d17a",
   "metadata": {},
   "source": [
    "**Observation:** Out of the total list of participants only 12.78% (258 out of 2018) are female politicians, while 87.21% (1760 out of 2018) are male. Upon considering the winners, 14.1% (76 out of 463) are female politicians, while 85.9% are male politicians. The Gender ratio is not very well distributed as can be seen from the above presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6808a5-9520-4deb-9e70-d768f49e41dc",
   "metadata": {},
   "source": [
    "### What is the Educational Qualification of our politicians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f4f86-36a0-40ea-9e46-88a87152e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "# Calculate overall education qualification counts\n",
    "ed_cnt = df.groupby('EDUCATION')['PARTY'].count().reset_index(name='Counts')\n",
    "\n",
    "# Add trace for overall education qualification\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=ed_cnt['EDUCATION'], values=ed_cnt['Counts'], pull=[0.1, 0.2, 0, 0.1, 0.2, 0, 0.1, 0.2, 0, 0.1, 0.2, 0.1],\n",
    "          title='Education Qualification Analysis of all'),\n",
    "    1, 1)\n",
    "\n",
    "# Filter out winners\n",
    "df_win = df[df['WINNER'] == 1]\n",
    "\n",
    "# Calculate education qualification counts for winners\n",
    "ed_win_cnt = df_win.groupby('EDUCATION')['PARTY'].count().reset_index(name='Counts')\n",
    "\n",
    "# Add trace for education qualification of winners\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=ed_win_cnt['EDUCATION'], values=ed_win_cnt['Counts'], pull=[0.1, 0.2, 0, 0.1, 0.2, 0, 0.1, 0.1, 0.2, 0, 0.1, 0.2], \n",
    "           title='Education Qualification of the Winners'),\n",
    "    1, 2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text='Education Qualification Analysis',  # Set the title\n",
    "    template='plotly_dark',                          # Use the 'plotly_dark' template\n",
    "    grid=dict(rows=1, columns=2),                     # Set the grid for subplots\n",
    "    height=500 \n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb40c0-4995-45de-9461-986911d3fa6a",
   "metadata": {},
   "source": [
    "**Observation:** The total percentage of Graduate+ educated people contesting in the election is 67.12%, which has increased to 72.17% of the winners. This is actually a positive sign, as educated politicians are a very big factor towards a country's development. But still around 28% of the politicians have received no professional degree. Hope with passing time, we improve upon this factor, and consider the educational qualification as a primary requirement while voting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769635e-9b2b-4879-ad00-fdafe78e262e",
   "metadata": {},
   "source": [
    "### What is the relationship of Age and Politics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d97175-a073-46f9-9c00-d208f2bb93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age and gender and count the number of politicians in each group\n",
    "age_cnt = df.groupby(['AGE', 'GENDER'])['NAME'].count().reset_index(name='Counts')\n",
    "\n",
    "# Create a histogram with violin plot marginal for age counts distribution among politicians\n",
    "fig = px.histogram(age_cnt, x=\"AGE\", y='Counts', color='GENDER', marginal='violin', title='Age Counts Distribution among the politicians')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text='Age Counts Distribution among the politicians',  # Set the title\n",
    "    template='plotly_dark',\n",
    "    width=800,  # Set the width of the plot\n",
    "    height=850  # Set the height of the plot\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d0809-1a30-4533-bc2f-fb12420cdd1c",
   "metadata": {},
   "source": [
    "**Observation:** Most Number of female politicians have their average age between 45-50, while for male politician, it ranges from 50-60 range. The average age of male politians is more as compared to female politicians contesting for the Lok Sabha elections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76ad59-40cf-4f23-8271-4f42cdd6f0b2",
   "metadata": {},
   "source": [
    "### What relation does the Politician category have with the election results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2b2b7-9e18-4936-b946-d63bb22c7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df\n",
    "# Calculate overall category counts\n",
    "cat_overall = df_cat.groupby('CATEGORY')['NAME'].count().reset_index(name='Counts')\n",
    "cat_overall['Category'] = 'Overall Category Counts'\n",
    "\n",
    "# Filter out winners\n",
    "winners = df[df['WINNER'] == 1]\n",
    "\n",
    "# Calculate category counts for winners\n",
    "cat_winner = winners.groupby('CATEGORY')['NAME'].count().reset_index(name='Counts')\n",
    "cat_winner['Category'] = 'Winning Category Ratio'\n",
    "\n",
    "# Concatenate overall and winner category counts\n",
    "cat_overl_win = pd.concat([cat_winner, cat_overall])\n",
    "\n",
    "# Create a grouped bar plot\n",
    "fig = px.bar(cat_overl_win, x='CATEGORY', y='Counts', color='Category', barmode='group')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text='Participation vs Win Counts for the Category in Politics',  # Set the title\n",
    "    template='plotly_dark')                                               \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0525f1-d7a6-4154-ae8a-d535a1b08793",
   "metadata": {},
   "source": [
    "**Observation:** The Category participation of General-SC-ST have been in the ratio of 68.97:18.97:12.04- while as of the winners, the ratios have been modified to 74.02:15.76:10:20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d36298d-4b13-47e6-9706-f712b1391eec",
   "metadata": {},
   "source": [
    "### Have the politicians been involved with criminal activities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d5bce-3aea-4eab-9324-12cff14e1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins for criminal cases ranges\n",
    "bins = [-1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, float('inf')]\n",
    "labels = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90-100', '100-above']\n",
    "\n",
    "# defining df_Criminal_range \n",
    "df_Criminal_range=df\n",
    "# Add a new column to the DataFrame indicating the bin for each criminal cases value\n",
    "df_Criminal_range['Criminal Cases Range'] = pd.cut(df_Criminal_range['CRIMINAL CASES'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Filter the DataFrame for winners and overall categories separately\n",
    "winners = df_Criminal_range[df_Criminal_range['WINNER'] == 1]\n",
    "overall = df_Criminal_range\n",
    "\n",
    "# Group by criminal cases range and count the number of politicians in each group for winners\n",
    "winners_grouped = winners.groupby('Criminal Cases Range').size().reset_index(name='Winner Counts')\n",
    "\n",
    "# Group by criminal cases range and count the number of politicians in each group for overall categories\n",
    "overall_grouped = overall.groupby('Criminal Cases Range').size().reset_index(name='Overall Counts')\n",
    "\n",
    "# Merge the results for winners and overall categories into a single DataFrame\n",
    "merged = pd.merge(winners_grouped, overall_grouped, on='Criminal Cases Range')\n",
    "\n",
    "# Plot the grouped counts\n",
    "fig = px.bar(merged, x='Criminal Cases Range', y=['Winner Counts', 'Overall Counts'],\n",
    "             barmode='group', labels={'value': 'Politicians Count', 'variable': 'Category'},\n",
    "             title='Winner and Overall Category Counts by Criminal Cases Range')\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626d4ef-d183-4ef7-a947-fc89536f6315",
   "metadata": {},
   "source": [
    "### Age Group wise Criminal Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6deb00-2b7d-4317-beb2-7041712cf8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the bins for age groups\n",
    "bins = [0, 20, 30, 40, 50, 60, 70, float('inf')]\n",
    "labels = ['Below 20', '20-30', '30-40', '40-50', '50-60', '60-70', '70 above']\n",
    "\n",
    "# defining df_Age_group is already defined and contains the necessary columns\n",
    "df_Age_group = df\n",
    "# Create a new column 'Age Group' with the bins\n",
    "df_Age_group['Age Group'] = pd.cut(df_Age_group['AGE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Group by 'Age Group' and count the number of criminals in each group\n",
    "criminal_counts = df_Age_group[df_Age_group['CRIMINAL CASES'] > 0].groupby('Age Group')['NAME'].count().reset_index(name='Criminal Count')\n",
    "\n",
    "# Create a bar chart with gradient colors\n",
    "fig = px.bar(criminal_counts, x='Age Group', y='Criminal Count',\n",
    "             title='Criminal Count by Age Group',\n",
    "             labels={'Criminal Count': 'Criminal Count', 'Age Group': 'Age Group'},\n",
    "             template='plotly_dark',\n",
    "             color='Criminal Count',  # Use 'Criminal Count' for color mapping\n",
    "             color_continuous_scale='viridis',  # Specify the color scale\n",
    "             )\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f3e98-ac82-477d-935f-e8b88b589a72",
   "metadata": {},
   "source": [
    "### Party Wise Count of Criminal Cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b872d-db62-491c-a137-1f9be5a369ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Group by 'PARTY' and count the number of criminal cases\n",
    "party_criminal_cases = df[df['CRIMINAL CASES'] > 0].groupby('PARTY')['CRIMINAL CASES'].count().reset_index()\n",
    "party_criminal_cases.columns = ['PARTY', 'Criminal Cases']\n",
    "\n",
    "# Select top 15 parties based on the count of criminal cases\n",
    "top_15_parties = party_criminal_cases.nlargest(15, 'Criminal Cases')\n",
    "\n",
    "# Create bar plot with color-coded bars\n",
    "fig = px.bar(top_15_parties, x='PARTY', y='Criminal Cases',\n",
    "             title='Count of Criminal Cases for Top 15 Parties',\n",
    "             labels={'Criminal Cases': 'Count of Criminal Cases', 'PARTY': 'Party'},\n",
    "             template='plotly_dark',\n",
    "             color='Criminal Cases',  # Color by the count of criminal cases\n",
    "             color_continuous_scale='viridis',  # Use a sequential color scale\n",
    "             )\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e2ca7-28d6-4cba-b018-8ffeb6b7293b",
   "metadata": {},
   "source": [
    "**Observations:** Many politicians have been associated with criminal activities. Always these cases pressed need not be genuine, but obviously, when its multiple- this is a serious issue. We must take the responsibility while voting, as its our duty to choose the right person- as a duty towards the nation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab710e28-409a-43f5-b352-871eaf59bb7f",
   "metadata": {},
   "source": [
    "### Plotting the Assets vs Liabilities amount for Winning Politicians (Plotted w.r.t State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d103fb-635b-47ef-9d35-c507a010358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Filter the DataFrame for winning politicians and sort by assets\n",
    "win_as_liab_name = df[df['WINNER'] == 1].sort_values(by='ASSETS', ascending=False)\n",
    "\n",
    "# Create the scatter plot using Plotly\n",
    "fig = px.scatter(win_as_liab_name, x='ASSETS', y='LIABILITIES', \n",
    "                 color='STATE', size='ASSETS', \n",
    "                 hover_data=['NAME', 'PARTY', 'CONSTITUENCY', 'STATE', 'WINNER'],\n",
    "                 title='Assets vs Liabilities for the Winning Politicians', template='plotly_dark')\n",
    "fig.update_layout(height=500)\n",
    "# Show the Plotly figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180ec11-df23-497e-9c01-8471bc5dc7f8",
   "metadata": {},
   "source": [
    "### For top 15 Parties ASSETS And LIABILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e47e68-7f82-464f-a4cc-ddae3a09ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Group by 'PARTY' and calculate total assets and liabilities\n",
    "party_assets_liabilities = df.groupby('PARTY').agg({'ASSETS': 'sum', 'LIABILITIES': 'sum'}).reset_index()\n",
    "\n",
    "# Select top 15 parties based on total assets\n",
    "top_15_parties = party_assets_liabilities.nlargest(15, 'ASSETS')\n",
    "\n",
    "# Melt the DataFrame to prepare for clustered column chart\n",
    "melted_df = pd.melt(top_15_parties, id_vars='PARTY', var_name='Financials', value_name='Amount')\n",
    "\n",
    "# Create clustered column chart\n",
    "fig = px.bar(melted_df, x='PARTY', y='Amount', color='Financials',\n",
    "             barmode='group', title='Assets and Liabilities for Top 15 Parties',\n",
    "             labels={'Amount': 'Amount (in Rupees)', 'PARTY': 'Party'}, template='plotly_dark')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58855394-9dd5-4dff-8fef-4b7c6ea04b9a",
   "metadata": {},
   "source": [
    "**Observations:** The assets and liabilities of the Winning politicians have been plotted. The parameters vary largely depending on the business/services they are associated with besides politics. No valid correlation could be inferred with respect to assets and liabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1e661-d528-44af-bbbf-50cc82eb371c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6f04c-5b35-48ee-b90a-00df7a703b0c",
   "metadata": {},
   "source": [
    "## DATA manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcc9e8-a744-4c59-b872-364f420b9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a767be-c52b-4179-9896-c7766c07ba77",
   "metadata": {},
   "source": [
    "* State: Uttar Pradesh, Maharashtra, West Bengal, 'Bihar', 'Tamil Nadu', 'Madhya Pradesh', 'Andhra Pradesh' top 7 CONSTITUENCY wise\n",
    "* Party: Top 20 Party\n",
    "* CONSTITUENCY, NAME, SYMBOL, GENERAL VOTES, POSTAL VOTES, OVER TOTAL VOTES POLLED IN CONSTITUENCY, Criminal Cases Range, Age Group : remove\n",
    "* Divide all education type: \n",
    "  1. High Education: This group will include education types such as 'Post Graduate', 'Doctorate', and 'Graduate Professional'.\n",
    "  2. \n",
    "Medium Education: This group will include education types such as 'Graduate' and '12th Pass'\n",
    "  3. \r\n",
    "Low Education: This group will include all other education types such as '10th Pass', '8th Pass', '5th Pass', 'Literate', 'Illiterate', 'Others', and 'Not Available'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487d176-e709-4515-82ae-8ed8ec92551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 state CONSTITUENCY wise\n",
    "Top7_selected_states = ['Uttar Pradesh', 'Maharashtra', 'West Bengal', 'Bihar', 'Tamil Nadu', 'Madhya Pradesh', 'Andhra Pradesh']\n",
    "df_7selected_states = df[df['STATE'].isin(Top7_selected_states)]\n",
    "# Print the column names of the DataFrame\n",
    "print(df_7selected_states.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ae37d-4ec5-44fe-a6b1-b14ecb983830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['CONSTITUENCY', 'NAME', 'SYMBOL', 'GENERAL VOTES', \n",
    "                   'POSTAL VOTES', 'OVER TOTAL VOTES POLLED IN CONSTITUENCY', \n",
    "                   'Criminal Cases Range', 'Age Group']\n",
    "cleaned_df_7selected_states = df_7selected_states.drop(columns=columns_to_drop)\n",
    "# Print the column names of the DataFrame\n",
    "print(cleaned_df_7selected_states.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7b350-91ab-4f44-8f78-358046139fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize education types into groups\n",
    "def categorize_education(education):\n",
    "    higher_education = ['Post Graduate', 'Doctorate', 'Graduate Professional']\n",
    "    standard_education = ['Graduate', '12th Pass']\n",
    "    if education in higher_education:\n",
    "        return 'Higher Education'\n",
    "    elif education in standard_education:\n",
    "        return 'Standard Education'\n",
    "    else:\n",
    "        return 'Primary Education'\n",
    "\n",
    "# Apply the categorize_education function to create a new column 'Education Group'\n",
    "cleaned_df_7selected_states['Education Group'] = cleaned_df_7selected_states['EDUCATION'].apply(categorize_education)\n",
    "cleaned_df_7selected_states_EG = cleaned_df_7selected_states.drop(columns= 'EDUCATION')\n",
    "\n",
    "# Use value_counts to get unique names and their counts in the 'Education Group' column\n",
    "education_group_counts = cleaned_df_7selected_states_EG['Education Group'].value_counts()\n",
    "\n",
    "# Print the unique names and their counts\n",
    "print(education_group_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb7da3-e121-47d6-a506-16356b231dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_7selected_states_EG.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4598a24f-0ddf-4a28-b490-c2be03f24a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of top 10 parties\n",
    "top_20_parties = ['BJP', 'INC', 'VBA', 'AITC', 'SHS' , 'BSP', 'CPI(M)', 'NCP', 'SP', 'IND','NTK','TDP','YSRCP','MNM','DMK','AIADMK','RJD','JnP','JD(U)','SBSP']\n",
    "\n",
    "# Filter the DataFrame to include only the top 10 parties\n",
    "candidates_df = cleaned_df_7selected_states_EG[cleaned_df_7selected_states_EG['PARTY'].isin(top_20_parties)]\n",
    "candidates_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ece032-d7b4-461e-956c-314736cd5fa5",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d03e4d-f48a-4c52-ac46-bb0e8f7874d7",
   "metadata": {},
   "source": [
    "### Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44034bf7-779f-4c01-b3ad-992acb2dfb22",
   "metadata": {},
   "outputs": [],
   "source": [
    " cat=candidates_df.dtypes==\"object\"\n",
    "cat_col=list(cat[cat].index)\n",
    "print(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa6bfc-7e87-401a-b0b0-291279de54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "State_counts = candidates_df['STATE'].value_counts()\n",
    "\n",
    "# Print the unique names and their counts\n",
    "print(State_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76c6f0-ce29-4c43-bb40-10b1d8e23860",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_candidates_df= pd.get_dummies(candidates_df, columns=['STATE', 'PARTY', 'GENDER', 'CATEGORY', 'Education Group'], drop_first=True, dtype=int)\n",
    "dummy_candidates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db209ded-4fda-45b5-abe0-7a2e06805882",
   "metadata": {},
   "source": [
    "### Outlier treatment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0988f60-771c-4ceb-94a5-6ca52fc86e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_candidates_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a64dd-9bf4-4c7b-8bf8-ed21f0c595d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,3))\n",
    "sns.boxplot(data=dummy_candidates_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89392c68-5cab-4402-bbc7-55d5674aa191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = dummy_candidates_df.quantile(0.25)\n",
    "Q3 = dummy_candidates_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter out outliers\n",
    "#df_no_outliers = dummy_candidates_df[~((dummy_candidates_df < (Q1 - 1.5 * IQR)) |(dummy_candidates_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Capping outliers for 'ASSETS' and 'LIABILITIES'\n",
    "dummy_candidates_df['ASSETS'] = dummy_candidates_df['ASSETS'].clip(lower=Q1['ASSETS'] - 1.5 * IQR['ASSETS'], upper=Q3['ASSETS'] + 1.5 * IQR['ASSETS'])\n",
    "dummy_candidates_df['LIABILITIES'] = dummy_candidates_df['LIABILITIES'].clip(lower=Q1['LIABILITIES'] - 1.5 * IQR['LIABILITIES'], upper=Q3['LIABILITIES'] + 1.5 * IQR['LIABILITIES'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e64f9-cb0d-4914-a0ef-fc8d8a47d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,3))\n",
    "sns.boxplot(data=dummy_candidates_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e94b4-ecec-4b25-82ee-018334a76062",
   "metadata": {},
   "source": [
    "### **The Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ccc1c-1d6f-4823-9ded-129a56b5bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corri = dummy_candidates_df.corr()\n",
    "mask = np.triu(np.ones_like(corri, dtype=bool))\n",
    "plt.figure(figsize=(25,19))\n",
    "sns.heatmap(corri, annot=True, mask = mask)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e00b5-e38f-4c88-9142-869ac77a2cad",
   "metadata": {},
   "source": [
    "#### **Variance Inflation Factor** (VIF) \n",
    "it is a measure used to quantify multicollinearity in a set of predictor variables in a regression analysis. It assesses how much the variance of an estimated regression coefficient is inflated due to multicollinearity in the model. High VIF values indicate high multicollinearity, which can cause issues with the interpretation and stability of the regression coefficients.\n",
    "\n",
    "**Treatment for High VIF:**\n",
    "Identify High VIF Variables: Look for variables with VIF values greater than a certain threshold, typically 10.\n",
    "\n",
    "**Address Multicollinearity:** High VIF values suggest that the variable is highly correlated with other predictor variables in the model. To address multicollinearity, consider the following options:\n",
    "\n",
    " 1. Remove the Variable: If the variable is not essential or redundant with other predictors, removing it can reduce multicollinearity.\n",
    " 2. Combine Variables: If two or more highly correlated variables are conceptually similar, you can create a composite variable by averaging or summing them.\n",
    " 3. Keep One Variable: Keep the variable with the most relevance to the research question or domain knowledge and remove the others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7a739-836e-431f-9e49-f80d113b2a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = dummy_candidates_df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(dummy_candidates_df.values, i) for i in range(dummy_candidates_df.shape[1])]\n",
    "\n",
    "print(vif)\n",
    "#If you find variables with a very high VIF (typically > 10), you may need to remove or combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bec89-7e36-4598-aec3-238e1bf93043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0fe8e9-12ad-4c84-96dd-b34ab9b87eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['TOTAL VOTES','TOTAL ELECTORS']\n",
    "\n",
    "# Remove or combine these variables from the dataset\n",
    "dummy_candidates_df_reduced = dummy_candidates_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Reassess VIF values for the remaining variables\n",
    "vif_reduced = pd.DataFrame()\n",
    "vif_reduced[\"Variable\"] = dummy_candidates_df_reduced.columns\n",
    "vif_reduced[\"VIF\"] = [variance_inflation_factor(dummy_candidates_df_reduced.values, i) for i in range(dummy_candidates_df_reduced.shape[1])]\n",
    "\n",
    "print(vif_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e1de2-587a-4d09-b77a-a3c240321954",
   "metadata": {},
   "source": [
    "### **x-y split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabad7b-4410-4031-8e0e-28a6b918f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_candidates_df_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb3f70-ffc0-43b0-925d-bbb2bc7088b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_multi = dummy_candidates_df_reduced.loc[:, dummy_candidates_df_reduced.columns !=\"WINNER\"]\n",
    "y_multi = dummy_candidates_df_reduced['WINNER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598fa02-0bc3-4fe8-adac-8f5ca4668a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_multi.shape, y_multi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71de1b0-a201-4894-8b1c-996b19cce17b",
   "metadata": {},
   "source": [
    "### **Test-Train Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d551dd0-fc06-4cc3-a17b-0044ca88bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_multi, y_multi ,test_size=0.2,random_state=0)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956eab9-581d-47ed-a772-a139094e117a",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98104df-4f23-45f8-b9a0-7f81e1848cc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_1: Multiple Logisctic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2d51c-d2fc-40dd-a91d-34731f260798",
   "metadata": {},
   "source": [
    "### Multiple Losgistic Regression using sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be38e16-e119-4447-a633-1e001029df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lrs_multi = LogisticRegression()\n",
    "clf_lrs_multi.fit(x_multi,y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546397c-f80f-4209-9697-e19eea1f386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lrs = clf_lrs_multi.predict(x_multi)\n",
    "\n",
    "acc_lrs = accuracy_score(y_multi, y_pred_lrs)\n",
    "f1_lrs = f1_score(y_multi, y_pred_lrs, average='weighted')\n",
    "roc_lrs = roc_auc_score(y_multi, y_pred_lrs)\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_multi, clf_lrs_multi.predict(x_multi)))\n",
    "print('Accuracy: ', acc_lrs,'\\nF1 Score: ', f1_lrs, '\\nAUC(ROC): ', roc_lrs )\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_multi, y_pred_lrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dad2df-94fa-4dc1-96fb-82dc4597e20f",
   "metadata": {},
   "source": [
    "The issue with getting zero values in the confusion matrix for logistic regression suggests that the model is failing to predict one of the classes. This could be due to several reasons, including issues with data preprocessing, class imbalance, or model parameters.\n",
    "Here are some steps to troubleshoot and rectify the issue:\n",
    "1. **Check Class Imbalance:** If your dataset is highly imbalanced (i.e., one class is significantly more frequent than the other), the logistic regression model might end up predicting only the majority class. You can use techniques such as oversampling the minority class, undersampling the majority class, or using SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "2. **Standardize Features:** Ensure that your features are standardized (i.e., they have zero mean and unit variance). Logistic regression can be sensitive to the scale of the features.\n",
    "3. **Adjust Threshold:** The default decision threshold for logistic regression is 0.5. If your data is imbalanced, adjusting this threshold can help improve the prediction of the minority class.\n",
    "4. **Regularization:** Ensure that you are using appropriate regularization. Logistic regression models often benefit from regularization (L1 or L2) to avoid overfitting and improve generalization.\n",
    "5. **Evaluate Model Performance:** Use metrics such as precision, recall, F1-score, and ROC-AUC to better understand model performance, especially in the context of imbalanced datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79252319-6e70-4a8b-9746-e0bbd7f434fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE()\n",
    "x_res, y_res = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_res)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Logistic Regression with regularization\n",
    "log_reg = LogisticRegression(C=0.01, penalty='l2', solver='liblinear')\n",
    "log_reg.fit(x_train_scaled, y_res)\n",
    "\n",
    "# Predict probabilities and adjust threshold\n",
    "y_prob = log_reg.predict_proba(x_train_scaled)[:, 1]\n",
    "threshold = 0.3\n",
    "y_train_pred_adjusted = (y_prob >= threshold).astype(int)\n",
    "acc_train_lrs = accuracy_score(y_train, y_train_pred_rfclf)\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_lrs)\n",
    "\n",
    "# Predict probabilities and adjust threshold for testing data\n",
    "y_prob = log_reg.predict_proba(x_test_scaled)[:, 1]\n",
    "threshold = 0.3\n",
    "y_pred_adjusted = (y_prob >= threshold).astype(int)\n",
    "\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_adjusted))\n",
    "\n",
    "acc_lrs_AT1 = accuracy_score(y_test, y_pred_adjusted)\n",
    "f1_lrs_AT1 = f1_score(y_test, y_pred_adjusted, average='weighted')\n",
    "roc_lrs_AT1 = roc_auc_score(y_test, y_pred_adjusted)\n",
    "\n",
    "print('Accuracy: ', acc_lrs_AT1, '\\nF1 Score: ', f1_lrs_AT1, '\\nAUC(ROC): ', roc_lrs_AT1)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_adjusted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c9d13-842a-41a9-b5e7-8061c0bc4b1e",
   "metadata": {},
   "source": [
    "### Multiple Logistic Regression using Statsmodel.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb7305-5617-41d5-85f4-49ac9f895209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sn\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "x_cons_multi = sn.add_constant(x_multi)\n",
    "logit_multi = sm.Logit(y_multi,x_cons_multi).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e3cab-e3bd-4a92-81bb-ea61b75c87d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit_multi.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e369595-138f-434a-bd76-80184da53a73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_2: Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0915129-26f4-4adc-ba5f-0e4e29ce5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf_lda = LinearDiscriminantAnalysis()\n",
    "clf_lda.fit(x_multi, y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b836ad70-9175-421a-b4c8-73f8e7aaa0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lda = clf_lda.predict(x_multi)\n",
    "\n",
    "acc_lda = accuracy_score(y_multi, y_pred_lda)\n",
    "f1_lda = f1_score(y_multi, y_pred_lda, average='weighted')\n",
    "roc_lda = roc_auc_score(y_multi, y_pred_lda)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_multi, clf_lda.predict(x_multi)))\n",
    "print('Accuracy: ', acc_lda,'\\nF1 Score: ', f1_lda, '\\nAUC(ROC): ', roc_lda)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_multi, y_pred_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a648b9b-b040-4694-8cc2-47857a036cb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_3: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fcd66-8e35-488e-865e-737fee625825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler1 = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_s= scaler1.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a725f-f6b4-4d00-8e9d-7eb3263df020",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = preprocessing.StandardScaler().fit(x_test)\n",
    "x_test_s= scaler2.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef247cc-d4fc-4c67-a5d9-ec2c1c5f6285",
   "metadata": {},
   "source": [
    "### KNN With n_neighbors = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65320865-11c2-4ac7-a56c-7d26657b79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf_knn_1.fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce52364-03bd-4eae-a93a-0036f192afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Trainng data \n",
    "acc_train_knn1 = accuracy_score(y_train, clf_knn_1.predict(x_train_s))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_knn1)\n",
    "\n",
    "# Testing data \n",
    "y_pred_knn1 = clf_knn_1.predict(x_test_s)\n",
    "acc_knn1 = accuracy_score(y_test, y_pred_knn1)\n",
    "f1_knn1 = f1_score(y_test, y_pred_knn1, average='weighted')\n",
    "roc_knn1 = roc_auc_score(y_test, y_pred_knn1)\n",
    "\n",
    "\n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, clf_knn_1.predict(x_test_s)))\n",
    "print('Accuracy: ', acc_knn1,'\\nF1 Score: ', f1_knn1, '\\nAUC(ROC): ', roc_knn1)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_knn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd528273-093e-4077-a10b-948cf97d8a5e",
   "metadata": {},
   "source": [
    "Achieving perfect scores on the training data with a complex model like a Random Forest, especially with a high number of estimators, is a strong indication of overfitting. The model is likely memorizing the training data rather than learning generalizable patterns. To address this, **tuning hyperparameters** (Use techniques like cross-validation and GridSearchCV to find optimal hyperparameters.) to improve generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e856cd8-093a-4a08-8346-2898fe3203bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### KNN With n_neighbors = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8a6fd-e986-4c93-b574-571580b53869",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn_3.fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac07984-f304-4c9b-a3ae-54ddc44e8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_knn3 = accuracy_score(y_train, clf_knn_3.predict(x_train_s))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_knn3)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, clf_knn_3.predict(x_test_s)))\n",
    "y_pred_knn3 = clf_knn_3.predict(x_test_s)\n",
    "\n",
    "acc_knn3 = accuracy_score(y_test, y_pred_knn3)\n",
    "f1_knn3 = f1_score(y_test, y_pred_knn3, average='weighted')\n",
    "roc_knn3 = roc_auc_score(y_test, y_pred_knn3)\n",
    "\n",
    "print('Accuracy: ', acc_knn3,'\\nF1 Score: ', f1_knn3, '\\nAUC(ROC): ', roc_knn3)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_knn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784f6b6-6d67-4b32-84f7-9bbce3e5b206",
   "metadata": {},
   "source": [
    "### Finding the Best K using Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2096acc-7587-47a6-802f-b9b6d835dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Creating a dictionary of n_neighbors\n",
    "params = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20,30,50,75,100],\n",
    "          'weights': ['uniform', 'distance'],\n",
    "          'p': [1, 2]}\n",
    "\n",
    "#creating a object\n",
    "grid_search_cv = GridSearchCV(KNeighborsClassifier(), params)\n",
    "grid_search_cv.fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba26446-2292-4a5a-a461-c8259900b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c80e6f-cf14-4a4e-9311-410b4a30aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_KNN = grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2fc4e4-269a-4f01-812e-fcf5b7c2e1f9",
   "metadata": {},
   "source": [
    "#### Model Performance After Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21227d7c-d509-4b4d-8fe7-9d3e5cac482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_knnop = accuracy_score(y_train, optimised_KNN.predict(x_train_s))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_knnop)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, optimised_KNN.predict(x_test_s)))\n",
    "y_pred_knnop = optimised_KNN.predict(x_test_s)\n",
    "\n",
    "acc_knnop = accuracy_score(y_test, y_pred_knnop)\n",
    "f1_knnop = f1_score(y_test, y_pred_knnop, average='weighted')\n",
    "roc_knnop = roc_auc_score(y_test, y_pred_knnop)\n",
    "\n",
    "print('Accuracy: ', acc_knnop,'\\nF1 Score: ', f1_knnop, '\\nAUC(ROC): ', roc_knnop)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_knnop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a6948-3973-45e5-91d8-0d59456e71b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_4: DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23265c-6ea1-41be-b661-4009565d137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clftree = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "clftree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b6f96-9370-4e6b-906e-1ad47c69da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clftree, out_file=None,feature_names= x_train.columns, filled = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702eff1-9942-44d6-9385-bc262cb82f2b",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de8afd-d2fb-422a-83f0-72beb43d3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_clftree = accuracy_score(y_train, clftree.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_clftree)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "y_pred_clftree = clftree.predict(x_test)\n",
    "\n",
    "acc_clftree = accuracy_score(y_test, y_pred_clftree)\n",
    "f1_clftree = f1_score(y_test, y_pred_clftree, average='weighted')\n",
    "roc_clftree = roc_auc_score(y_test, y_pred_clftree)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, clftree.predict(x_test)))\n",
    "print('Accuracy: ', acc_clftree,'\\nF1 Score: ', f1_clftree, '\\nAUC(ROC): ', roc_clftree)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_clftree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c22162-5467-4f1a-bda9-65cfa2ffa6ac",
   "metadata": {},
   "source": [
    "### Controlling Tree growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b29e9-9c86-40c7-813f-f99c7b8c0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "clftree2 = tree.DecisionTreeClassifier(min_samples_leaf = 20, max_depth=4)\n",
    "clftree2.fit(x_train, y_train)\n",
    "dot_data1 = tree.export_graphviz(clftree2, out_file=None,feature_names= x_train.columns, filled = True)\n",
    "graph2 = pydotplus.graph_from_dot_data(dot_data1)\n",
    "Image(graph2.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f9a52-75e7-4577-b06b-f1b84132267a",
   "metadata": {},
   "source": [
    "#### Model Performance after Controlling the tree growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd60839-ccb5-4efe-94d5-3bfaebc3a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_clftree2 = accuracy_score(y_train, clftree2.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_clftree2)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, clftree2.predict(x_test)))\n",
    "y_pred_clftree2 = clftree2.predict(x_test)\n",
    "\n",
    "acc_clftree2 = accuracy_score(y_test, y_pred_clftree2)\n",
    "f1_clftree2 = f1_score(y_test, y_pred_clftree2, average='weighted')\n",
    "roc_clftree2 = roc_auc_score(y_test, y_pred_clftree2)\n",
    "\n",
    "print('Accuracy: ', acc_clftree2,'\\nF1 Score: ', f1_clftree2, '\\nAUC(ROC): ', roc_clftree2)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_clftree2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23030a-8b8d-4d24-a265-8fd9d0a7df05",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641f541-416e-46bc-ba83-08cf8ef5645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clftree3 = tree.DecisionTreeClassifier()\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(base_estimator=clftree3, n_estimators=1000,\n",
    "                            bootstrap=True, n_jobs=-1,\n",
    "                            random_state=42)\n",
    "bag_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1f984-f615-42b0-91d7-593f8a265d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_bag = accuracy_score(y_train, bag_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_bag)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, bag_clf.predict(x_test)))\n",
    "y_pred_bag = bag_clf.predict(x_test)\n",
    "\n",
    "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
    "f1_bag = f1_score(y_test, y_pred_bag, average='weighted')\n",
    "roc_bag = roc_auc_score(y_test, y_pred_bag)\n",
    "\n",
    "print('Accuracy: ', acc_bag,'\\nF1 Score: ', f1_bag, '\\nAUC(ROC): ', roc_bag)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff41cd-f900-496c-87dc-7231d778869c",
   "metadata": {},
   "source": [
    "Achieving perfect scores on the training data with a complex model like a Random Forest, especially with a high number of estimators, is a strong indication of overfitting. The model is likely memorizing the training data rather than learning generalizable patterns. To address this, **tuning hyperparameters** (Use techniques like cross-validation and GridSearchCV to find optimal hyperparameters.) to improve generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7043f575-9d4c-415e-b20e-308540911ce9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_5: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f144d4-c77b-4552-bdc7-5cd34ff16179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1 ,random_state=42)\n",
    "rf_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6908fa4-6789-472a-a95d-d56bb5c8f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_rfclf = accuracy_score(y_train, rf_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_rfclf)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,  rf_clf.predict(x_test)))\n",
    "y_pred_rfclf = rf_clf.predict(x_test)\n",
    "\n",
    "acc_rfclf = accuracy_score(y_test, y_pred_rfclf)\n",
    "f1_rfclf = f1_score(y_test, y_pred_rfclf, average='weighted')\n",
    "roc_rfclf = roc_auc_score(y_test, y_pred_rfclf)\n",
    "\n",
    "print('Accuracy: ', acc_rfclf,'\\nF1 Score: ', f1_rfclf, '\\nAUC(ROC): ', roc_rfclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931ac5a-b66a-45f1-98cc-9a6850771ad7",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "Achieving perfect scores on the training data with a complex model like a Random Forest, especially with a high number of estimators, is a strong indication of overfitting. The model is likely memorizing the training data rather than learning generalizable patterns. To address this, **tuning hyperparameters** (Use techniques like cross-validation and GridSearchCV to find optimal hyperparameters.) to improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08367d-d1fd-4cb7-aab0-96802c997eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_clf_grid = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42)\n",
    "params_grid = {\"max_features\" : [4,5,6,7,8,9,10],\n",
    "              \"min_samples_split\": [2, 3, 6, 10],}\n",
    "grid_search = GridSearchCV(rf_clf_grid, params_grid,\n",
    "                           n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_\n",
    "cvrf_clf = grid_search.best_estimator_\n",
    "\n",
    "# Trainng data \n",
    "acc_train_cvrf_clf = accuracy_score(y_train, cvrf_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_cvrf_clf)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,  cvrf_clf.predict(x_test)))\n",
    "y_pred_cvrf_clf = cvrf_clf.predict(x_test)\n",
    "\n",
    "acc_cvrf_clf = accuracy_score(y_test, y_pred_cvrf_clf)\n",
    "f1_cvrf_clf = f1_score(y_test, y_pred_cvrf_clf, average='weighted')\n",
    "roc_cvrf_clf = roc_auc_score(y_test, y_pred_cvrf_clf)\n",
    "\n",
    "print('Accuracy: ', acc_cvrf_clf,'\\nF1 Score: ', f1_cvrf_clf, '\\nAUC(ROC): ', roc_cvrf_clf)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_cvrf_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216783ef-11f1-477f-8e6e-2f346bf7d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'max_features' : [4,5,7,10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "print(grid_search.best_params_)\n",
    "best_rf_clf = grid_search.best_estimator_\n",
    "\n",
    "# Training data metrics\n",
    "acc_train_cvrfclf1 = accuracy_score(y_train, best_rf_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_cvrfclf1)\n",
    "\n",
    "# Test data metrics\n",
    "y_test_pred_cvrfclf = best_rf_clf.predict(x_test)\n",
    "\n",
    "acc_test_cvrfclf1 = accuracy_score(y_test, y_test_pred_cvrfclf)\n",
    "f1_test_cvrfclf1 = f1_score(y_test, y_test_pred_cvrfclf, average='weighted')\n",
    "roc_test_cvrfclf1 = roc_auc_score(y_test, y_test_pred_cvrfclf)\n",
    "test_class_report = classification_report(y_test, y_test_pred_cvrfclf)\n",
    "\n",
    "print(\"\\nTest Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,   best_rf_clf.predict(x_test)))\n",
    "print('Accuracy: ', acc_test_rfclf1,'\\nF1 Score: ', f1_test_rfclf1,'\\AUC(ROC): ', roc_test_rfclf1)\n",
    "print(\"Classification Report:\\n\", test_class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2b0e4-4912-44b8-872f-47b7a38c01b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_6: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfd2f6-d1d7-4a95-9a85-2534f410a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_clf = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                     max_features=6,\n",
    "                                     min_samples_split=2,\n",
    "                                     random_state=42)\n",
    "gbc_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a2d60-7b4b-4d97-95e4-a68dab0689bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_gbc_clf = accuracy_score(y_train, gbc_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_gbc_clf)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,   gbc_clf.predict(x_test)))\n",
    "y_pred_gbc_clf = gbc_clf.predict(x_test)\n",
    "\n",
    "acc_gbc_clf = accuracy_score(y_test, y_pred_gbc_clf)\n",
    "f1_gbc_clf = f1_score(y_test, y_pred_gbc_clf, average='weighted')\n",
    "roc_gbc_clf = roc_auc_score(y_test, y_pred_gbc_clf)\n",
    "\n",
    "print('Accuracy: ', acc_gbc_clf,'\\nF1 Score: ', f1_gbc_clf, '\\nAUC(ROC): ', roc_gbc_clf)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_gbc_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea827bb-32f2-4afd-820f-2cfd38f22092",
   "metadata": {},
   "source": [
    "### GB Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bc95b-c6e6-48c5-b984-a1048b965172",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_clf_grid = GradientBoostingClassifier(loss='log_loss',\n",
    "                                          criterion='friedman_mse',\n",
    "                                          random_state=42)\n",
    "params_grid_gbc = {\"learning_rate\": np.arange(0.01,0.11,0.01),\n",
    "                   \"n_estimators\" : [500,700,1000],\n",
    "                   \"max_depth\": [1,2,3,4,5],}\n",
    "grid_search_gbc = GridSearchCV(gbc_clf_grid, params_grid_gbc,\n",
    "                           n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_search_gbc.fit(x_train, y_train)\n",
    "print('Best Params: ', grid_search_gbc.best_params_)\n",
    "cvgbc_clf = grid_search_gbc.best_estimator_\n",
    "\n",
    "\n",
    "# Trainng data \n",
    "acc_train_cvgbc_clf = accuracy_score(y_train, cvgbc_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_cvgbc_clf)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,   cvgbc_clf.predict(x_test)))\n",
    "y_pred_cvgbc_clf = cvgbc_clf.predict(x_test)\n",
    "\n",
    "acc_cvgbc_clf = accuracy_score(y_test, y_pred_cvgbc_clf)\n",
    "f1_cvgbc_clf = f1_score(y_test, y_pred_cvgbc_clf, average='weighted')\n",
    "roc_cvgbc_clf = roc_auc_score(y_test, y_pred_cvgbc_clf)\n",
    "\n",
    "print('Accuracy: ', acc_cvgbc_clf,'\\nF1 Score: ', f1_cvgbc_clf, '\\nAUC(ROC): ', roc_cvgbc_clf)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_cvgbc_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94beba3f-2664-464c-bf66-4bda66a93acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define GradientBoostingClassifier with initial parameters\n",
    "gbc_clf_grid = GradientBoostingClassifier(loss='log_loss', criterion='friedman_mse', random_state=42)\n",
    "\n",
    "params_grid_gbc = {\n",
    "    \"learning_rate\": np.arange(0.01, 0.05, 0.01),  # Lower learning rate\n",
    "    \"n_estimators\": [100, 200, 300],  # Moderate number of estimators\n",
    "    \"max_depth\": [1, 2],  # Further reduced depth\n",
    "    \"min_samples_split\": [5, 10, 15],  # Higher min_samples_split\n",
    "    \"min_samples_leaf\": [4, 6, 8],  # Higher min_samples_leaf\n",
    "    \"subsample\": [0.8, 0.9, 1.0],  # Subsample\n",
    "    \"max_features\": ['sqrt', 'log2', None]  # Regularization using max_features\n",
    "}\n",
    "\n",
    "# Implement GridSearchCV with cross-validation\n",
    "grid_search_gbc = GridSearchCV(gbc_clf_grid, params_grid_gbc, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_search_gbc.fit(x_train, y_train)\n",
    "\n",
    "print('Best Params: ', grid_search_gbc.best_params_)\n",
    "cvgbc_clf2 = grid_search_gbc.best_estimator_\n",
    "\n",
    "# Training data metrics\n",
    "y_train_pred_cvgbc_clf2 = cvgbc_clf2.predict(x_train)\n",
    "acc_train_cvgbc_clf2 = accuracy_score(y_train, y_train_pred_cvgbc_clf2)\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_cvgbc_clf2)\n",
    "\n",
    "# Test data metrics\n",
    "y_test_pred_cvgbc_clf2 = cvgbc_clf2.predict(x_test)\n",
    "acc_test_cvgbc_clf2 = accuracy_score(y_test, y_test_pred_cvgbc_clf2)\n",
    "f1_test_cvgbc_clf2 = f1_score(y_test, y_test_pred_cvgbc_clf2, average='weighted')\n",
    "roc_test_cvgbc_clf2 = roc_auc_score(y_test, y_test_pred_cvgbc_clf2)\n",
    "\n",
    "print(\"\\nTest Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred_cvgbc_clf2))\n",
    "print('Accuracy: ', acc_test_cvgbc_clf2, '\\nF1 Score: ', f1_test_cvgbc_clf2, '\\nAUC(ROC): ', roc_test_cvgbc_clf2)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred_cvgbc_clf2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67332f-265b-49bf-82f2-e428626e01d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_7: Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13967966-92d6-41ec-a0c1-06ee6f792e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(learning_rate =0.02, n_estimators =5000)\n",
    "ada_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd5b15-d821-4b2d-9072-b8e880b884ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_ada_clf = accuracy_score(y_train, ada_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_ada_clf)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,  ada_clf.predict(x_test)))\n",
    "y_pred_ada_clf = ada_clf.predict(x_test)\n",
    "\n",
    "acc_ada_clf = accuracy_score(y_test, y_pred_ada_clf)\n",
    "f1_ada_clf = f1_score(y_test, y_pred_ada_clf, average='weighted')\n",
    "roc_ada_clf = roc_auc_score(y_test, y_pred_ada_clf)\n",
    "\n",
    "print('Accuracy: ', acc_ada_clf,'\\nF1 Score: ', f1_ada_clf, '\\nAUC(ROC): ', roc_ada_clf)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_ada_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d7c2b-f50c-4676-857e-920335d82c9c",
   "metadata": {},
   "source": [
    "### Using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6322c5-a4f3-45c9-9ae5-a6e9418df551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the base estimator\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2)  # You can experiment with different depths\n",
    "\n",
    "# Define the AdaBoost model with the new base estimator\n",
    "ada_clf_grid = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Reduce the number of estimators\n",
    "params_grid_ada = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_ada = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), random_state=42), \n",
    "                               params_grid_ada, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_search_ada.fit(x_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "print('Best Params: ', grid_search_ada.best_params_)\n",
    "cv_ada_clf = grid_search_ada.best_estimator_\n",
    "\n",
    "# Training data metrics\n",
    "acc_train_cv_ada_clf = accuracy_score(y_train, cv_ada_clf.predict(x_train))\n",
    "\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_cv_ada_clf)\n",
    "\n",
    "\n",
    "# Test data metrics\n",
    "y_test_pred_cv_ada_clf = cv_ada_clf.predict(x_test)\n",
    "acc_test_cv_ada_clf = accuracy_score(y_test, y_test_pred_cv_ada_clf)\n",
    "f1_test_cv_ada_clf = f1_score(y_test, y_test_pred_cv_ada_clf, average='weighted')\n",
    "roc_test_cv_ada_clf = roc_auc_score(y_test, y_test_pred_cv_ada_clf)\n",
    "\n",
    "print(\"\\nTest Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred_cv_ada_clf))\n",
    "print('Accuracy: ', acc_test_cv_ada_clf,'\\nF1 Score: ', f1_test_cv_ada_clf,'\\nAUC(ROC): ', roc_test_cv_ada_clf)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred_cv_ada_clf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858511b0-de9a-4ba9-8abf-407aa071a216",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model_08: XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5432d1f-3c56-4213-9a5c-55f02ffc6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=5, n_estimators=10000, learning_rate=0.3,\n",
    "                            n_jobs=-1, random_state=42)\n",
    "xgb_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b9747-8c63-476f-903b-ecbe6770d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng data \n",
    "acc_train_xgb_clf = accuracy_score(y_train, xgb_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_xgb_clf)\n",
    "\n",
    "# Testing data \n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,  xgb_clf.predict(x_test)))\n",
    "y_pred_xgb_clf = xgb_clf.predict(x_test)\n",
    "\n",
    "acc_xgb_clf = accuracy_score(y_test, y_pred_xgb_clf)\n",
    "f1_xgb_clf = f1_score(y_test, y_pred_xgb_clf, average='weighted')\n",
    "roc_xgb_clf = roc_auc_score(y_test, y_pred_xgb_clf)\n",
    "\n",
    "print('Accuracy: ', acc_xgb_clf,'\\nF1 Score: ', f1_xgb_clf, '\\nAUC(ROC): ', roc_xgb_clf)\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_xgb_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e85caf-4bb7-4020-98da-55857555e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb_clf = xgb.XGBClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_xgb_clf = grid_search.best_estimator_\n",
    "print('Best Params: ', grid_search.best_params_)\n",
    "\n",
    "# Train the best model\n",
    "best_xgb_clf.fit(x_train, y_train)\n",
    "\n",
    "# Training data metrics\n",
    "acc_train_cvxgb_clf = accuracy_score(y_train, best_xgb_clf.predict(x_train))\n",
    "print(\"Training Data Metrics:\")\n",
    "print('Accuracy: ', acc_train_cvxgb_clf)\n",
    "\n",
    "\n",
    "# Test data metrics\n",
    "y_pred_cvxgb_clf = best_xgb_clf.predict(x_test)\n",
    "acc_cvxgb_clf = accuracy_score(y_test, y_pred_cvxgb_clf)\n",
    "f1_cvxgb_clf = f1_score(y_test, y_pred_cvxgb_clf, average='weighted')\n",
    "roc_cvxgb_clf = roc_auc_score(y_test, y_pred_cvxgb_clf)\n",
    "\n",
    "print(\"\\nTesting Data Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,  best_xgb_clf.predict(x_test)))\n",
    "print('Accuracy: ', acc_cvxgb_clf,'\\nF1 Score: ', f1_cvxgb_clf,'\\nAUC(ROC): ', roc_cvxgb_clf)\n",
    "print(\"Classification Report:\\n\",classification_report(y_test, y_pred_xgb_clf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0e451-cefc-4144-b44c-a7108389ede8",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1137f9-4136-4774-aa41-06341d31d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (replace these with your actual data)\n",
    "train_accuracies = [None, acc_train_lrs, None, acc_train_knn1, acc_train_knn3, acc_train_knnop, acc_train_clftree, acc_train_clftree2, acc_train_bag, acc_train_rfclf, acc_train_cvrf_clf, acc_train_cvrfclf1, acc_train_gbc_clf, acc_train_cvgbc_clf, acc_train_cvgbc_clf2, acc_train_ada_clf, acc_train_cv_ada_clf, acc_train_xgb_clf, acc_train_cvxgb_clf]\n",
    "test_accuracies = [acc_lrs, acc_lrs_AT1, acc_lda, acc_knn1, acc_knn3, acc_knnop, acc_clftree, acc_clftree2, acc_bag, acc_rfclf, acc_cvrf_clf, acc_test_cvrfclf1, acc_gbc_clf, acc_cvgbc_clf, acc_test_cvgbc_clf2, acc_ada_clf, acc_test_cv_ada_clf, acc_xgb_clf, acc_cvxgb_clf]\n",
    "f_score = [f1_lrs, f1_lrs_AT1, f1_lda, f1_knn1, f1_knn3, f1_knnop, f1_clftree, f1_clftree2, f1_bag, f1_rfclf, f1_cvrf_clf, f1_test_cvrfclf1, f1_gbc_clf, f1_cvgbc_clf, f1_test_cvgbc_clf2, f1_ada_clf, f1_test_cv_ada_clf, f1_xgb_clf, f1_cvxgb_clf]\n",
    "roc_auc = [roc_lrs, roc_lrs_AT1, roc_lda, roc_knn1, roc_knn3, roc_knnop, roc_clftree, roc_clftree2, roc_bag, roc_rfclf, roc_cvrf_clf, roc_test_cvrfclf1, roc_gbc_clf, roc_cvgbc_clf, roc_test_cvgbc_clf2, roc_ada_clf, roc_test_cv_ada_clf, roc_xgb_clf, roc_cvxgb_clf]\n",
    "model_types = ['LogisticReg', 'LogisticReg_grid', 'LDA', 'KNN_1', 'KNN_2', 'KNN_Grid', 'DecisionTree', 'DecisionTree_2', 'DecisionTree_Bagging', 'RandomForest', 'RandomForest_Grid1', 'RandomForest_Grid2', 'GradientBoosting_1', 'GradientBoosting_Grid', 'GradientBoosting_Grid2', 'AdaBoost_1', 'AdaBoost_grid', 'XGB', 'XGB_Grid']\n",
    "\n",
    "# Create DataFrame\n",
    "final_df = pd.DataFrame({\n",
    "    \"Model Type\": model_types,\n",
    "    \"Train_Accuracies\": train_accuracies,\n",
    "    \"Test_Accuracies\": test_accuracies,\n",
    "    \"F1 Scores\": f_score,\n",
    "    \"ROC AUC\": roc_auc\n",
    "})\n",
    "\n",
    "# Convert None to np.nan for sorting purposes\n",
    "final_df['Train_Accuracies'] = final_df['Train_Accuracies'].apply(lambda x: float(x) if x is not None else None)\n",
    "\n",
    "# Create a boolean column to mark if Train_Accuracies is equal to 1\n",
    "final_df['Train_Acc_Not_1'] = final_df['Train_Accuracies'] != 1.0\n",
    "\n",
    "# Sort by the boolean column and then by Test_Accuracies in descending order\n",
    "final_df_s = final_df.sort_values(by=['Train_Acc_Not_1', 'Test_Accuracies'], ascending=[False, False])\n",
    "\n",
    "# Drop the boolean column as it's no longer needed\n",
    "final_df_s = final_df_s.drop(columns=['Train_Acc_Not_1'])\n",
    "\n",
    "# Round the values\n",
    "final_df_s = final_df_s.round(4)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# Table plot\n",
    "ax[0].axis('off')\n",
    "table = ax[0].table(cellText=final_df_s.values, colLabels=final_df_s.columns, cellLoc='center', loc='center', colWidths=[0.27, 0.20, 0.19, 0.15, 0.15])\n",
    "\n",
    "# Change background color\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.0, 2.25)\n",
    "\n",
    "# Set table colors\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    cell.set_edgecolor('black')\n",
    "    if i == 0:  # Header\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "        cell.set_facecolor('black')\n",
    "    else:\n",
    "        cell.set_facecolor('lightgrey')\n",
    "        cell.set_text_props(color='black')\n",
    "\n",
    "# Add title above the table\n",
    "ax[0].text(0.5, 1.1, 'Sorted Dataframe by Test Accuracy (Descending):', horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "# Bar plot\n",
    "sns.barplot(x=\"Test_Accuracies\", y=\"Model Type\", data=final_df_s, palette=\"viridis\", ax=ax[1])\n",
    "ax[1].set_xlim(0.7, 0.99)\n",
    "ax[1].set_xlabel(\"Accuracies\", fontsize=10, fontweight='bold')\n",
    "ax[1].set_ylabel(\"Model Type\", fontsize=10, fontweight='bold')\n",
    "ax[1].set_title(\"Model Type vs Accuracies\", horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8761571-36f2-4d41-8f82-42e11ba474a3",
   "metadata": {},
   "source": [
    "# Out Put of the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cd6cb-8909-4731-aedc-1b364b6d50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = dummy_candidates_df_reduced.columns\n",
    "\n",
    "# print the column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320ebe4-6fd8-4b37-913a-6a87f6d05092",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_candidates_df_reduced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362be0e2-a25e-4ce0-99f4-5e1534f82e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming the model is stored in rf_classifier_tuned\n",
    "\n",
    "def input_features():\n",
    "    feature_names = [\n",
    "        'CRIMINAL CASES', 'AGE', 'ASSETS', 'LIABILITIES', 'OVER TOTAL ELECTORS IN CONSTITUENCY', \n",
    "        'STATE_Bihar', 'STATE_Madhya Pradesh', 'STATE_Maharashtra', 'STATE_Tamil Nadu', 'STATE_Uttar Pradesh', \n",
    "        'STATE_West Bengal', 'PARTY_AITC', 'PARTY_BJP', 'PARTY_BSP', 'PARTY_CPI(M)', 'PARTY_DMK', 'PARTY_INC', \n",
    "        'PARTY_IND', 'PARTY_JD(U)', 'PARTY_JnP', 'PARTY_MNM', 'PARTY_NCP', 'PARTY_NTK', 'PARTY_RJD', 'PARTY_SBSP', \n",
    "        'PARTY_SHS', 'PARTY_SP', 'PARTY_TDP', 'PARTY_VBA', 'PARTY_YSRCP', 'GENDER_MALE', 'CATEGORY_SC', 'CATEGORY_ST', \n",
    "        'Education Group_Primary Education', 'Education Group_Standard Education'\n",
    "    ]\n",
    "    \n",
    "    feature_ranges = {\n",
    "        'CRIMINAL CASES': (0.0, 28.0), 'AGE': (25.0, 86.0), 'ASSETS': (0.0, 227574800.0), 'LIABILITIES': (0.0, 15666280.0), \n",
    "        'OVER TOTAL ELECTORS IN CONSTITUENCY': (0.489755, 51.456884), 'STATE_Bihar': (0, 1), 'STATE_Madhya Pradesh': (0, 1), \n",
    "        'STATE_Maharashtra': (0, 1), 'STATE_Tamil Nadu': (0, 1), 'STATE_Uttar Pradesh': (0, 1), 'STATE_West Bengal': (0, 1), \n",
    "        'PARTY_AITC': (0, 1), 'PARTY_BJP': (0, 1), 'PARTY_BSP': (0, 1), 'PARTY_CPI(M)': (0, 1), 'PARTY_DMK': (0, 1), \n",
    "        'PARTY_INC': (0, 1), 'PARTY_IND': (0, 1), 'PARTY_JD(U)': (0, 1), 'PARTY_JnP': (0, 1), 'PARTY_MNM': (0, 1), \n",
    "        'PARTY_NCP': (0, 1), 'PARTY_NTK': (0, 1), 'PARTY_RJD': (0, 1), 'PARTY_SBSP': (0, 1), 'PARTY_SHS': (0, 1), \n",
    "        'PARTY_SP': (0, 1), 'PARTY_TDP': (0, 1), 'PARTY_VBA': (0, 1), 'PARTY_YSRCP': (0, 1), 'GENDER_MALE': (0, 1), \n",
    "        'CATEGORY_SC': (0, 1), 'CATEGORY_ST': (0, 1), 'Education Group_Primary Education': (0, 1), \n",
    "        'Education Group_Standard Education': (0, 1)\n",
    "    }\n",
    "    \n",
    "    features = []\n",
    "    print(\"Please enter the candidate details:\")\n",
    "    for feature in feature_names:\n",
    "        min_val, max_val = feature_ranges[feature]\n",
    "        value = float(input(f\"{feature} (min: {min_val}, max: {max_val}): \"))\n",
    "        \n",
    "        # Ensuring the value is within the range\n",
    "        if value < min_val or value > max_val:\n",
    "            print(f\"Warning: {feature} value should be between {min_val} and {max_val}.\")\n",
    "        \n",
    "        features.append(value)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def predict_winner(model, features):\n",
    "    features_array = np.array([features])  # Convert list to 2D array to match the input shape for prediction\n",
    "    prediction = model.predict(features_array)\n",
    "    return prediction[0]\n",
    "\n",
    "# Example: Assuming the model is already trained and stored in ADA boostig Grid search\n",
    "features = input_features()\n",
    "predicted_winner = predict_winner(cv_ada_clf, features)\n",
    "print(f\"The prediction for WINNER is: {'Yes' if predicted_winner == 1 else 'No'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
